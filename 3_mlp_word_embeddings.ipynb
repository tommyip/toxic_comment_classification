{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP classifier with word embeddings representation\n",
    "\n",
    "In the previous attempts, the comments text has been represented using a bag-of-words model. We were able to attain a respectable score, however, it is clear that it has trouble generalizing to new data. Words that brings toxicity are often times made up on the spot, so how ever big our token count dictionary is it can't cover the test set appropriately. N-grams made maginal improvements to the model, which is disappointing. My theory is that toxic words are usually concatenated to a single token (eg _cock\\*\\*er_) so the captured n-grams (where n > 1) are just uninformative English phrases.\n",
    "\n",
    "In this notebook, we instead represent each comment as a dense word vector. We use a pre-trained model included with spaCy to vectorize each token, then we take the mean of the vectors as the document vector. Each document vector is fed into a multi-layered perceptron to predict the probabilites for each labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "from helper import train_validation_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validation, x_test, y_train, y_validation, y_test = train_validation_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment2vec(text):\n",
    "    doc = nlp(text)\n",
    "    # Some times a sentense consist entirely of stop words and non-alpha characters,\n",
    "    # we simply use all tokens in those cases.\n",
    "    if sum(token.is_alpha for token in doc) > 10:\n",
    "        tokens = [token.vector for token in doc if token.is_alpha]\n",
    "    else:\n",
    "        tokens = [token.vector for token in doc]\n",
    "    return np.mean(np.vstack(tokens), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus2matrix(corpus):\n",
    "    mat = np.zeros((len(corpus), 300), dtype=np.float32)\n",
    "    for vec, text in zip(mat, corpus):\n",
    "        vec[:] = comment2vec(text)\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vec = corpus2matrix(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 3.12207724\n",
      "Validation score: 0.898000\n",
      "Iteration 2, loss = 1.39896767\n",
      "Validation score: 0.900000\n",
      "Iteration 3, loss = 0.89650666\n",
      "Validation score: 0.900000\n",
      "Iteration 4, loss = 0.76909411\n",
      "Validation score: 0.900000\n",
      "Iteration 5, loss = 0.68172936\n",
      "Validation score: 0.900000\n",
      "Iteration 6, loss = 0.61459606\n",
      "Validation score: 0.898000\n",
      "Iteration 7, loss = 0.56311488\n",
      "Validation score: 0.896000\n",
      "Iteration 8, loss = 0.52075052\n",
      "Validation score: 0.900000\n",
      "Iteration 9, loss = 0.49154285\n",
      "Validation score: 0.906000\n",
      "Iteration 10, loss = 0.47120626\n",
      "Validation score: 0.906000\n",
      "Iteration 11, loss = 0.45510609\n",
      "Validation score: 0.904000\n",
      "Iteration 12, loss = 0.44369261\n",
      "Validation score: 0.904000\n",
      "Iteration 13, loss = 0.43413240\n",
      "Validation score: 0.902000\n",
      "Iteration 14, loss = 0.42555208\n",
      "Validation score: 0.904000\n",
      "Iteration 15, loss = 0.41783812\n",
      "Validation score: 0.906000\n",
      "Iteration 16, loss = 0.41244502\n",
      "Validation score: 0.910000\n",
      "Iteration 17, loss = 0.40927603\n",
      "Validation score: 0.904000\n",
      "Iteration 18, loss = 0.40043886\n",
      "Validation score: 0.914000\n",
      "Iteration 19, loss = 0.39573231\n",
      "Validation score: 0.912000\n",
      "Iteration 20, loss = 0.39087078\n",
      "Validation score: 0.912000\n",
      "Iteration 21, loss = 0.38689192\n",
      "Validation score: 0.912000\n",
      "Iteration 22, loss = 0.38368689\n",
      "Validation score: 0.918000\n",
      "Iteration 23, loss = 0.37971140\n",
      "Validation score: 0.912000\n",
      "Iteration 24, loss = 0.37448307\n",
      "Validation score: 0.912000\n",
      "Iteration 25, loss = 0.37150132\n",
      "Validation score: 0.918000\n",
      "Iteration 26, loss = 0.37015075\n",
      "Validation score: 0.918000\n",
      "Iteration 27, loss = 0.36608530\n",
      "Validation score: 0.918000\n",
      "Iteration 28, loss = 0.36104917\n",
      "Validation score: 0.920000\n",
      "Iteration 29, loss = 0.35815400\n",
      "Validation score: 0.916000\n",
      "Iteration 30, loss = 0.35578194\n",
      "Validation score: 0.918000\n",
      "Iteration 31, loss = 0.35198666\n",
      "Validation score: 0.918000\n",
      "Iteration 32, loss = 0.34962796\n",
      "Validation score: 0.918000\n",
      "Iteration 33, loss = 0.34738501\n",
      "Validation score: 0.920000\n",
      "Iteration 34, loss = 0.34430114\n",
      "Validation score: 0.920000\n",
      "Iteration 35, loss = 0.34199834\n",
      "Validation score: 0.920000\n",
      "Iteration 36, loss = 0.33915071\n",
      "Validation score: 0.920000\n",
      "Iteration 37, loss = 0.33677216\n",
      "Validation score: 0.916000\n",
      "Iteration 38, loss = 0.33505985\n",
      "Validation score: 0.918000\n",
      "Iteration 39, loss = 0.33250465\n",
      "Validation score: 0.920000\n",
      "Iteration 40, loss = 0.33129093\n",
      "Validation score: 0.922000\n",
      "Iteration 41, loss = 0.32971486\n",
      "Validation score: 0.924000\n",
      "Iteration 42, loss = 0.32587801\n",
      "Validation score: 0.918000\n",
      "Iteration 43, loss = 0.32393445\n",
      "Validation score: 0.920000\n",
      "Iteration 44, loss = 0.32159686\n",
      "Validation score: 0.918000\n",
      "Iteration 45, loss = 0.32009380\n",
      "Validation score: 0.918000\n",
      "Iteration 46, loss = 0.31815643\n",
      "Validation score: 0.916000\n",
      "Iteration 47, loss = 0.31690290\n",
      "Validation score: 0.918000\n",
      "Iteration 48, loss = 0.31458338\n",
      "Validation score: 0.916000\n",
      "Iteration 49, loss = 0.31237249\n",
      "Validation score: 0.916000\n",
      "Iteration 50, loss = 0.31107832\n",
      "Validation score: 0.918000\n",
      "Iteration 51, loss = 0.30942079\n",
      "Validation score: 0.914000\n",
      "Iteration 52, loss = 0.30956966\n",
      "Validation score: 0.914000\n",
      "Iteration 53, loss = 0.30779126\n",
      "Validation score: 0.910000\n",
      "Iteration 54, loss = 0.30631439\n",
      "Validation score: 0.914000\n",
      "Iteration 55, loss = 0.30411453\n",
      "Validation score: 0.916000\n",
      "Iteration 56, loss = 0.30178430\n",
      "Validation score: 0.918000\n",
      "Iteration 57, loss = 0.30166816\n",
      "Validation score: 0.916000\n",
      "Iteration 58, loss = 0.29817267\n",
      "Validation score: 0.910000\n",
      "Iteration 59, loss = 0.29826441\n",
      "Validation score: 0.918000\n",
      "Iteration 60, loss = 0.29582275\n",
      "Validation score: 0.916000\n",
      "Iteration 61, loss = 0.29818812\n",
      "Validation score: 0.914000\n",
      "Iteration 62, loss = 0.29279153\n",
      "Validation score: 0.914000\n",
      "Iteration 63, loss = 0.29075568\n",
      "Validation score: 0.912000\n",
      "Iteration 64, loss = 0.29100464\n",
      "Validation score: 0.914000\n",
      "Iteration 65, loss = 0.28798113\n",
      "Validation score: 0.914000\n",
      "Iteration 66, loss = 0.28644305\n",
      "Validation score: 0.912000\n",
      "Iteration 67, loss = 0.28624809\n",
      "Validation score: 0.910000\n",
      "Validation score did not improve more than tol=0.000100 for 25 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(50,),\n",
    "    random_state=42,\n",
    "    max_iter=300,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=25,\n",
    "    verbose=True\n",
    ").fit(x_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation & tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our initial neural network with one hidden layer of size 100, the training score is reaching 1.0 while validation score is in the low 0.9s. This is a significant improvement over the previous Naive Bayes model, however, there also seems to be some overfitting. Deeper networks also overfitted wihout improving performance. We enabled the `early_stopping` option which stops training when validation scores stop improving to combat this problem. This also decrease training time which is a plus.\n",
    "\n",
    "The tuned model uses one hidden layer of size 50, which exhibits good generalization and validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_validation_vec = corpus2matrix(x_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ROC AUC: 0.9756677652855248\n",
      "Validation ROC AUC: 0.9516890736679461\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict_proba(x_train_vec)\n",
    "y_validation_pred = model.predict_proba(x_validation_vec)\n",
    "\n",
    "print('Train ROC AUC:', roc_auc_score(y_train, y_train_pred))\n",
    "print('Validation ROC AUC:', roc_auc_score(y_validation, y_validation_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC: 0.965614779659225\n"
     ]
    }
   ],
   "source": [
    "x_test_vec = corpus2matrix(x_test)\n",
    "y_test_pred = model.predict_proba(x_test_vec)\n",
    "print('Test ROC AUC:', roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.94993349, 0.988347  , 0.97138947, 0.99498495, 0.96367297,\n",
       "       0.92536079])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_test_pred, average=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using word embeddings and neural networks improved our test scores by over 20% compared to the naive bayes model. Labels with relatively little training data also performs quite well. In the next notebook we will attempt to retrain the pretrained word vectors to improve coverage, as well as try using more sophisticated architectures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
